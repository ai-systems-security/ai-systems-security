## Hi there üëã

<!--
**ai-systems-security/ai-systems-security** is a ‚ú® _special_ ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- üî≠ I‚Äôm currently working on ...
- üå± I‚Äôm currently learning ...
- üëØ I‚Äôm looking to collaborate on ...
- ü§î I‚Äôm looking for help with ...
- üí¨ Ask me about ...
- üì´ How to reach me: ...
- üòÑ Pronouns: ...
- ‚ö° Fun fact: ...
-->

# AI Systems Security Experiments üõ°Ô∏èü§ñ

[![Profile Views](https://komarev.com/ghpvc/?username=ai-systems-security&color=blue)](https://github.com/ai-systems-security)  
[![GitHub followers](https://img.shields.io/github/followers/ai-systems-security?label=Follow&style=social)](https://github.com/ai-systems-security?tab=followers)  
[![GitHub stars](https://img.shields.io/github/stars/ai-systems-security?style=social)](https://github.com/ai-systems-security)

Welcome to my **AI Security Experiments** profile! This repository collection explores **security risks in AI Agents** and **adversarial machine learning in financial AI systems**.  
Hands-on projects demonstrate vulnerabilities in multi-agent systems, unsafe AI operations, and adversarial attacks on machine learning models.

---

## üöÄ Highlights

### Attacking Insecure Agents
- Excessive Database Agency: LLMs issuing unrestricted queries like `MATCH (n) RETURN n` on Neo4j.  
- Multi-Agent Manipulation: Prompt-engineered attacks influencing collaborative AI agents.  
- Prompt Injection & Policy Bypass: Tricks agents into leaking sensitive information.  
- Unsafe Tool Execution: Exploits AI agents with unrestricted tool access.

### Financial AI Security
- Evasion attacks on credit scoring models (tabular data).  
- Black-box and white-box attacks using ART and Foolbox.  
- Future roadmap includes model extraction, inference attacks, poisoning, and defenses.  

### üéØ Goals
- Simulate real-world attacks on AI agents and financial AI systems.  
- Explore mitigations: guardrails, whitelisting, monitoring, robust training.  
- Provide a hands-on learning environment for AI security research.

---

## üõ†Ô∏è Tools & Tech
- **Python 3.10+**  
- **Neo4j Desktop / Server (APOC enabled)**  
- **Ollama (local LLM) or any Generative AI**  
- **LangGraph, LangChain, ART, Foolbox**

### Running Experiments
- Agent experiments: `jupyter notebook: excessive_db_agency1.ipynb, excessive_db_agency2.ipynb`  
- Adversarial ML on credit scoring: `jupyter notebook: bim_attack-art-logistic_regression.ipynb, cw_attack-art-logistic_regression.ipynb, deepfool_attack-art-logistic_regression.ipynb, ead_attack-art-logistic_regression.ipynb, fgm_attack-art-logistic_regression.ipynb, jsma_attack-art-logistic_regression.ipynb, pgd_attack-art-logistic_regression.ipynb, boundary _attack(targeted)_attack-art-logistic_regression.ipynb, boundary _attack(untargeted)_attack-art-logistic_regression.ipynb, hsj_attack-art-logistic_regression.ipynb, zoo_attack-art-logistic_regression.ipynb`

---

## üìä GitHub Stats
![ai-systems-security's GitHub stats](https://github-readme-stats.vercel.app/api?username=ai-systems-security&show_icons=true&hide_title=true&count_private=true&theme=radical)

![Top Languages](https://github-readme-stats.vercel.app/api/top-langs/?username=ai-systems-security&layout=compact&theme=radical)

---

## ‚ö†Ô∏è Security Notes
- For **educational purposes only**.  
- Do **not deploy vulnerable agents** or ML models in production.  
- Always enforce: whitelisting, tool guardrails, interaction monitoring, policy & prompt security, adversarially robust ML defenses.

---

## üìö References
- [OWASP Top 10 for LLM Applications](https://owasp.org/www-project-top-10-for-llm-applications/)  
- [OWASP ML Security Top 10 (2023)](https://owasp.org/www-project-machine-learning-security-top-10/)  
- [LangGraph Documentation](https://python.langchain.com/docs/langgraph)  
- [Neo4j Graph Database](https://neo4j.com/)  
- [Adversarial Robustness Toolbox (ART)](https://github.com/Trusted-AI/adversarial-robustness-toolbox)  
- [Agentic AI research papers & security advisories]  

---

Thanks for visiting my profile! üëã
